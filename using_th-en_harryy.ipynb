{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_xVLVRugHLQ"
   },
   "source": [
    "# Login HuggingFace to Upload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iF67agq1kcA9"
   },
   "outputs": [],
   "source": [
    "# !git config --global credential.helper store\n",
    "\n",
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.17.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, DatasetDict, Dataset\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def pre_process_from_csv(path, n_row=100000):\n",
    "    df_5M = pd.read_csv(path, nrows=n_row)\n",
    "    list_5M = df_5M.to_dict('records')\n",
    "    list_sub = ['LST_Corpus']*len(list_5M)\n",
    "    dict_5M = pd.DataFrame({\"translation\": list_5M, \"subdataset\": list_sub})\n",
    "    return dict_5M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = pre_process_from_csv('TEST_dataset_5M.csv', 1000000)\n",
    "\n",
    "cut_datasets = DatasetDict()\n",
    "cut_datasets = Dataset.from_pandas(raw_datasets, split=\"train+validation\").train_test_split(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation', 'subdataset'],\n",
       "        num_rows: 800000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation', 'subdataset'],\n",
       "        num_rows: 200000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?cut_datasets.push_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut_datasets.push_to_hub(repo_id=\"huak95/TNANA_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95015a960fc4624bb4e8b4bfbfda5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/800 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca619824674c4eb887d3dabd795580e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/200 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cut_datasets.save_to_disk('fuck_thth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-th-en\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"translate English to Romanian: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_len  = 128\n",
    "max_target_len = 128\n",
    "\n",
    "source_lang = 'th'\n",
    "target_lang = 'en'\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + ex[source_lang] for ex in examples['translation']]\n",
    "    targets = []\n",
    "    for ex_ in examples['translation']:\n",
    "        ex = ex_[source_lang]\n",
    "        if ex is not None:\n",
    "            targets.append(ex)\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_len, truncation=True) # Pad to longest word (128 char)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        try:\n",
    "            labels = tokenizer(targets, max_length=max_target_len, truncation=True)\n",
    "        except:\n",
    "            print('targets: ', targets)\n",
    "\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987ef046dc7346a7a4b18b47bc9ce9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b8b800480241b5b1fdf6000337585d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = cut_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation', 'subdataset', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 80000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation', 'subdataset', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8GqEX7grMTu"
   },
   "source": [
    "# 2. Using Translation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbLxzsQFv6Ct"
   },
   "source": [
    "### Using AutoModel (With model selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "5f4c398c1f10479a9e593488e0288e13",
      "7379aad4cd5e443d87b8847c774730dd",
      "96bc72f5d2ab456c82ef93b9d1daae28",
      "9b9da8145682432b9e5c2c06fca1c7bd",
      "4a3154f8a418429d878d1ee69a23c384",
      "7db78072ae744fed884109b073112f16",
      "689c1ba0fe78498ab93862605dc13dfb",
      "579336e1b91a46f4b71a97166f7ad9bb",
      "cb1beb192231451a91497cce0537c10f",
      "0fe56995037840feb8d1b190a702dc53",
      "f7b13cea9b6f488fab4038319465b9f2",
      "0c03cf489288455ca73c7e9908bf93d6",
      "34c5e1e8d63d45a78593df8c4726a2af",
      "15baaa76664f41bcaa2b3d48368ea13b",
      "200f4e3d4c7445089bf84db41d02389d",
      "90786043cba94b52bf6a69676d84f49a",
      "d5173325310e4d36b217ef2c408b9784",
      "1178ab5e4a57412191c45a89f4d899c0",
      "fca6ce728fde4cdd8a819bdf558b163b",
      "bd4f8116bb0846a7ae8ed63159da24f5",
      "25c37fe96d68472b9bbfb6bd18c628de",
      "4c21a738a5284584b12bf3ca177579a4",
      "ba5f236325d04fa3bc297bd830c7af18",
      "1948d677fba34c9ba5bdbacc6dc8d5f0",
      "415afa813b014861ba9f082adfa83a91",
      "b56c0437a66e411ab4d169f02a211a67",
      "4deba2d529ce455684e4b6e059edab41",
      "9e5b9c3e27e146a0aadc98d241fe690b",
      "de715baa70c84245813a93c75c620118",
      "d63d0de90900413997bdb843657f56a0",
      "db58ea79429f48448809dbe9cdc4c8c9",
      "06495f9f21d547f385b1f6ff2df634b2",
      "efce4e270011493db42c4950a3f6e91f",
      "b2012e1abb7d4dfe87f00c80592c1d83",
      "7a7d6b8d8196415398311188ea6582fc",
      "f41f7e25c51b44c69dc2f05a8e06750b",
      "d75cf9a5d4204a27aa9f7707e8e202f6",
      "5cdd3f171ae14516b216397c45fc348e",
      "71957595cfd2480189d994a242050a8b",
      "674d82fe3edb4705b0a0a4cbafc22a71",
      "c190d9118f774c94a163261596bd83e8",
      "f16d43478f1145ccbe046d1aa6ad7a01",
      "c548e8569af8409ab05600aa746eaf29",
      "6f26805251bb461b85543ad11de84f9e"
     ]
    },
    "id": "6Lx1d4UBtvod",
    "outputId": "24c869ab-7c78-4741-8a1c-2b3e37833079",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149f9a66779642a29d0f4202100f28ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8672b3f8a84a4c398a34974313650908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "model_pretrain = \"Helsinki-NLP/opus-mt-th-en\"\n",
    "# model_for_predict = \"./opus-mt-th-en-finetuned-5k-th-to-en\"\n",
    "model_for_predict = \"huak95/opus-mt-th-en-finetuned-5k-th-to-en\"\n",
    "\n",
    "model_pt = AutoModelForSeq2SeqLM.from_pretrained(model_pretrain)\n",
    "model    = AutoModelForSeq2SeqLM.from_pretrained(model_for_predict)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git lfs track \"opus-mt-th-en-finetuned-5k-th-to-en/*\"\n",
    "\n",
    "# model.push_to_hub('huak95/opus-mt-th-en-finetuned-5k-th-to-en')\n",
    "# # tokenizer.push_to_hub('huak95/opus-mt-th-en-finetuned-5k-th-to-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harry_translate(input_texts, model=model_pt):\n",
    "    inputs = tokenizer(input_texts['th'], return_tensors = \"pt\")\n",
    "\n",
    "    outputs = model.generate(inputs[\"input_ids\"],\n",
    "                             max_length=40,\n",
    "                             num_beams=4,\n",
    "                             early_stopping=True)\n",
    "\n",
    "    return tokenizer.decode(outputs[0]).replace('<pad> ',''), input_texts['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'en': 'he wears glasses.', 'th': 'เขา ใส่ แว่น .'},\n",
       " {'en': 'kate this is kaoru', 'th': 'เค ท นี่ คือ คา โอ รุ'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['test']['translation'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "pv48je1-uYIi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thai_text: เอา ล่ะ\n",
      "real_text:  here we go\n",
      "pred_text:  เอา และ\n",
      "pre_train:  All right.\n",
      "\n",
      "thai_text: ฉัน ไป ทำ ธุระ ที่นั่น ทุกๆ สาม เดือน .\n",
      "real_text:  i go there on business every three months.\n",
      "pred_text:  ฉัน ไป ทํา ส่วน ที่นั่นที่ ทุกหลัง สาม \n",
      "pre_train:  I do business there every three months.\n",
      "\n",
      "thai_text: โปรด ตัด ผม ออก จาก แผนการ ของ คุณ ที่ จะไป เล่น สกี ใน วัน สุดสัปดาห์ นี้\n",
      "real_text:  please count me out of your plans to go skiing for the weekend .\n",
      "pred_text:  โปรด ตั้ง ผม ออก จาก แรงการ ของ คุณ ที่\n",
      "pre_train:  Please cut me off from your plans to go skiing this weekend\n",
      "\n",
      "thai_text: ขอบคุณ กรุณา มา อีก\n",
      "real_text:  thank you very much please come again\n",
      "pred_text:  ขอบคุณ กรุณา มา อีก\n",
      "pre_train:  Thank you. Please come again.\n",
      "\n",
      "thai_text: เม็ด เหงื่อ ผุด ขึ้น บน หน้าผาก ของ เธอ\n",
      "real_text:  beads of perspiration gathered in her on her forehead\n",
      "pred_text:  และ น้ําหรับ แข่ ขึ้น บน หมาย ของ เธอ\n",
      "pre_train:  The sweatdrops on her forehead\n",
      "\n",
      "thai_text: วาด อิสระ\n",
      "real_text:  free hand\n",
      "pred_text:  แม้ อย่าง\n",
      "pre_train:  Draw Freedom\n",
      "\n",
      "thai_text: ฉัน ขอ ชีส เค้ก หนึ่ง ชิ้น ได้ไหม ?\n",
      "real_text:  could i have a slice of cheese cake?\n",
      "pred_text:  ฉัน ขอ เสีย คิด หนึ่ง ช่วย ได้ไหม?\n",
      "pre_train:  Can I have a piece of cheese cake?\n",
      "\n",
      "thai_text: คอมพิวเตอร์ นี้ ไม่ ทำงาน ถูกต้อง\n",
      "real_text:  this computer isn't working right\n",
      "pred_text:  เครื่องครั้ง นี้ ไม่ ทํางาน ถูก\n",
      "pre_train:  This computer doesn't work right.\n",
      "\n",
      "thai_text: มาก เกิน ไป\n",
      "real_text:  go over the odds\n",
      "pred_text:  มาก เกิน ไป\n",
      "pre_train:  Too Much\n",
      "\n",
      "thai_text: หน่อย ตะโกน ใส่ ป้อม ว่า \" นาย นี่ โง่ จัง ทำ อะไร ก็ ไม่ ถูก เหรอ \"\n",
      "real_text:  noi yelled at pom \" you ’ re a pinhead. don ’ t you know how to do anything right ? \"\n",
      "pred_text:  ห้อง กระเสียง ใส่ แข่ง ว่า \" นุ่ง นี้ \n",
      "pre_train:  And cried unto the strong, saying, Thou art foolish: is it not right that thou doest so?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,110):\n",
    "    text_ = tokenized_datasets['test']['translation'][i]\n",
    "    thai_text = text_['th']\n",
    "    pred_text_pt, real_text = harry_translate(text_, model_pt)\n",
    "    pred_text, real_text    = harry_translate(text_, model)\n",
    "    \n",
    "#     m_score = compute_metrics.compute(predictions=[pred_text], references=[real_text])\n",
    "\n",
    "    print('thai_text:',  thai_text)\n",
    "    print('real_text: ', real_text)\n",
    "    print('pred_text: ', pred_text)\n",
    "    print('pre_train: ', pred_text_pt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harry_translate_from_text(input_texts, model=model_pt):\n",
    "    inputs = tokenizer(input_texts, return_tensors = \"pt\")\n",
    "\n",
    "    outputs = model.generate(inputs[\"input_ids\"],\n",
    "                             max_length=40,\n",
    "                             num_beams=4,\n",
    "                             early_stopping=True)\n",
    "\n",
    "    return tokenizer.decode(outputs[0]).replace('<pad> ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "metric = datasets.load_metric('sacrebleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e230b7dd18743518c398d5c8192dea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/951 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-e5ba37169cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgold_references\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mharry_translate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#     print(model_input, \"__\", gold_ref, \"__\", model_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-c75abbb4b1d3>\u001b[0m in \u001b[0;36mharry_translate_from_text\u001b[0;34m(input_texts, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mharry_translate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     outputs = model.generate(inputs[\"input_ids\"],\n\u001b[1;32m      5\u001b[0m                              \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2437\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2438\u001b[0m                 \u001b[0;34m\"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m                 \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "\n",
    "evaluation_df = pd.DataFrame(cut_datasets['test']['translation'][0:1000]).dropna(subset='en')\n",
    "evaluation_dataset = evaluation_df.to_numpy()\n",
    "\n",
    "model_inputs, gold_refs, model_preds = [], [], []\n",
    "for gold_references, model_input in tqdm(evaluation_dataset):\n",
    "    \n",
    "    model_pred = harry_translate_from_text(model_input, model)\n",
    "#     print(model_input, \"__\", gold_ref, \"__\", model_pred)\n",
    "    \n",
    "    model_preds.append(model_pred)\n",
    "    \n",
    "#     metric.add_batch(predictions=model_predictions.split(' '), references=[gold_references.split(' ')])\n",
    "# final_score = metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>th</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>effort without effect</td>\n",
       "      <td>ความ พยายาม ที่ ไร้ ผล</td>\n",
       "      <td>a futile attempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what colors did you have in mind</td>\n",
       "      <td>คุณ มี สี อะไร อยู่ ในใจ</td>\n",
       "      <td>what color do you have in mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my apartment isn't that big.</td>\n",
       "      <td>อพาร์ตเมนต์ ของ ฉัน ไม่ ได้ ใหญ่ ขนาด นั้น .</td>\n",
       "      <td>my apartment isn't that big.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what can i spread on this bread</td>\n",
       "      <td>ฉัน สามารถ ทา อะไร บน ขนมปัง นี้ ได้</td>\n",
       "      <td>can i put anything on this bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the wall stood fast</td>\n",
       "      <td>กำแพง ตั้งตระหง่าน</td>\n",
       "      <td>a towering wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Some experts would say that those words seem m...</td>\n",
       "      <td>ผู้ ​ เชี่ยวชาญ ​ บาง ​ คน ​ คง ​ จะ ​ บอก ​ ว...</td>\n",
       "      <td>some experts would say that those words seem t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>aim high</td>\n",
       "      <td>ตั้ง เป้าหมาย ไว้ สูง</td>\n",
       "      <td>set a high goal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>Rain Forests I read with great interest your s...</td>\n",
       "      <td>จาก ​ ผู้ ​ อ่าน ​ ของ ​ เรา</td>\n",
       "      <td>from our reader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>could you put me through to mr murphy please</td>\n",
       "      <td>คุณ สามารถ นำ ฉัน ไปยัง คุณ เมอ ร ์ ฟ ี ่ ได้ไ...</td>\n",
       "      <td>could you take me to mr. murf please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>a blood bank</td>\n",
       "      <td>ธนาคาร เลือด</td>\n",
       "      <td>blood bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    en  \\\n",
       "0                                effort without effect   \n",
       "1                     what colors did you have in mind   \n",
       "2                         my apartment isn't that big.   \n",
       "3                      what can i spread on this bread   \n",
       "4                                  the wall stood fast   \n",
       "..                                                 ...   \n",
       "760  Some experts would say that those words seem m...   \n",
       "761                                           aim high   \n",
       "762  Rain Forests I read with great interest your s...   \n",
       "763       could you put me through to mr murphy please   \n",
       "764                                       a blood bank   \n",
       "\n",
       "                                                    th  \\\n",
       "0                               ความ พยายาม ที่ ไร้ ผล   \n",
       "1                             คุณ มี สี อะไร อยู่ ในใจ   \n",
       "2         อพาร์ตเมนต์ ของ ฉัน ไม่ ได้ ใหญ่ ขนาด นั้น .   \n",
       "3                 ฉัน สามารถ ทา อะไร บน ขนมปัง นี้ ได้   \n",
       "4                                   กำแพง ตั้งตระหง่าน   \n",
       "..                                                 ...   \n",
       "760  ผู้ ​ เชี่ยวชาญ ​ บาง ​ คน ​ คง ​ จะ ​ บอก ​ ว...   \n",
       "761                              ตั้ง เป้าหมาย ไว้ สูง   \n",
       "762                       จาก ​ ผู้ ​ อ่าน ​ ของ ​ เรา   \n",
       "763  คุณ สามารถ นำ ฉัน ไปยัง คุณ เมอ ร ์ ฟ ี ่ ได้ไ...   \n",
       "764                                       ธนาคาร เลือด   \n",
       "\n",
       "                                                  pred  \n",
       "0                                     a futile attempt  \n",
       "1                       what color do you have in mind  \n",
       "2                         my apartment isn't that big.  \n",
       "3                     can i put anything on this bread  \n",
       "4                                      a towering wall  \n",
       "..                                                 ...  \n",
       "760  some experts would say that those words seem t...  \n",
       "761                                    set a high goal  \n",
       "762                                    from our reader  \n",
       "763               could you take me to mr. murf please  \n",
       "764                                         blood bank  \n",
       "\n",
       "[731 rows x 3 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "test_bleu_df = copy.deepcopy(evaluation_df.iloc[0:len(model_preds)])\n",
    "test_bleu_df['pred'] = model_preds\n",
    "test_bleu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.8/dist-packages (2.0.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.4.4)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.8.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (1.19.4)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2.4.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2022.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BLEU = 45.07 70.6/42.9/36.4/37.5 (BP = 1.000 ratio = 1.000 hyp_len = 17 ref_len = 17)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install sacrebleu\n",
    "\n",
    "def cal_bleu(predict, ground_truth):\n",
    "  \"\"\"\n",
    "  this function calculate bleu score between prediction and ground truth\n",
    "  predict <List> : list of prediction string [\"str1\",\"str2\",\"str3\", ...]\n",
    "  ground_truth <List> : list of groundtruth string [\"gt1\",\"gt2\",\"gt3\", ...]\n",
    "  \"\"\"\n",
    "  from sacrebleu.metrics import BLEU\n",
    "  bleu = BLEU()\n",
    "  res = score = bleu.corpus_score(ground_truth, [predict])\n",
    "  return res\n",
    "\n",
    "refs = ['The dog bit the man.', 'It was not unexpected.', 'The man bit him first.',]\n",
    "sys = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n",
    "\n",
    "cal_bleu(sys, refs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>th</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>effort without effect</td>\n",
       "      <td>ความ พยายาม ที่ ไร้ ผล</td>\n",
       "      <td>a futile attempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what colors did you have in mind</td>\n",
       "      <td>คุณ มี สี อะไร อยู่ ในใจ</td>\n",
       "      <td>what color do you have in mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my apartment isn't that big.</td>\n",
       "      <td>อพาร์ตเมนต์ ของ ฉัน ไม่ ได้ ใหญ่ ขนาด นั้น .</td>\n",
       "      <td>my apartment isn't that big.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what can i spread on this bread</td>\n",
       "      <td>ฉัน สามารถ ทา อะไร บน ขนมปัง นี้ ได้</td>\n",
       "      <td>can i put anything on this bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the wall stood fast</td>\n",
       "      <td>กำแพง ตั้งตระหง่าน</td>\n",
       "      <td>a towering wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Some experts would say that those words seem m...</td>\n",
       "      <td>ผู้ ​ เชี่ยวชาญ ​ บาง ​ คน ​ คง ​ จะ ​ บอก ​ ว...</td>\n",
       "      <td>some experts would say that those words seem t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>aim high</td>\n",
       "      <td>ตั้ง เป้าหมาย ไว้ สูง</td>\n",
       "      <td>set a high goal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>Rain Forests I read with great interest your s...</td>\n",
       "      <td>จาก ​ ผู้ ​ อ่าน ​ ของ ​ เรา</td>\n",
       "      <td>from our reader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>could you put me through to mr murphy please</td>\n",
       "      <td>คุณ สามารถ นำ ฉัน ไปยัง คุณ เมอ ร ์ ฟ ี ่ ได้ไ...</td>\n",
       "      <td>could you take me to mr. murf please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>a blood bank</td>\n",
       "      <td>ธนาคาร เลือด</td>\n",
       "      <td>blood bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    en  \\\n",
       "0                                effort without effect   \n",
       "1                     what colors did you have in mind   \n",
       "2                         my apartment isn't that big.   \n",
       "3                      what can i spread on this bread   \n",
       "4                                  the wall stood fast   \n",
       "..                                                 ...   \n",
       "760  Some experts would say that those words seem m...   \n",
       "761                                           aim high   \n",
       "762  Rain Forests I read with great interest your s...   \n",
       "763       could you put me through to mr murphy please   \n",
       "764                                       a blood bank   \n",
       "\n",
       "                                                    th  \\\n",
       "0                               ความ พยายาม ที่ ไร้ ผล   \n",
       "1                             คุณ มี สี อะไร อยู่ ในใจ   \n",
       "2         อพาร์ตเมนต์ ของ ฉัน ไม่ ได้ ใหญ่ ขนาด นั้น .   \n",
       "3                 ฉัน สามารถ ทา อะไร บน ขนมปัง นี้ ได้   \n",
       "4                                   กำแพง ตั้งตระหง่าน   \n",
       "..                                                 ...   \n",
       "760  ผู้ ​ เชี่ยวชาญ ​ บาง ​ คน ​ คง ​ จะ ​ บอก ​ ว...   \n",
       "761                              ตั้ง เป้าหมาย ไว้ สูง   \n",
       "762                       จาก ​ ผู้ ​ อ่าน ​ ของ ​ เรา   \n",
       "763  คุณ สามารถ นำ ฉัน ไปยัง คุณ เมอ ร ์ ฟ ี ่ ได้ไ...   \n",
       "764                                       ธนาคาร เลือด   \n",
       "\n",
       "                                                  pred  \n",
       "0                                     a futile attempt  \n",
       "1                       what color do you have in mind  \n",
       "2                         my apartment isn't that big.  \n",
       "3                     can i put anything on this bread  \n",
       "4                                      a towering wall  \n",
       "..                                                 ...  \n",
       "760  some experts would say that those words seem t...  \n",
       "761                                    set a high goal  \n",
       "762                                    from our reader  \n",
       "763               could you take me to mr. murf please  \n",
       "764                                         blood bank  \n",
       "\n",
       "[731 rows x 3 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bleu_df_small = test_bleu_df.dropna(subset='en')\n",
    "test_bleu_df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BLEU = 20.65 45.0/24.8/15.9/10.3 (BP = 1.000 ratio = 1.176 hyp_len = 8056 ref_len = 6849)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_bleu(test_bleu_df_small['pred'].to_list(), test_bleu_df_small['en'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some fucking git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut_datasets.save_to_disk('fuck_thth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# git lfs install\n",
    "# git clone https://huggingface.co/datasets/huak95/TNANA\n",
    "# # if you want to clone without large files – just their pointers\n",
    "# # prepend your git clone with the following env var:\n",
    "# GIT_LFS_SKIP_SMUDGE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# cd TNANA\n",
    "# git add .\n",
    "# git commit -m 'Add THANA'\n",
    "# git config --global user.name \"huak95\"\n",
    "# git push\n",
    "# ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
